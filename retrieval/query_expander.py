"""Query expansion via LLM for improved retrieval."""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING

from core.config import settings

if TYPE_CHECKING:
    from openai import OpenAI

logger = logging.getLogger(__name__)


def expand_query(query: str, openai_client: OpenAI | None = None) -> str:
    """Expand short query into detailed technical question using LLM.

    Args:
        query: Original user query
        openai_client: Optional OpenAI client instance

    Returns:
        Expanded query with more context and detail
    """
    if openai_client is None:
        from openai import OpenAI

        openai_client = OpenAI(api_key=settings.openai_api_key)

    system_prompt = (
        "You are a query expansion expert. "
        "Expand the user's short query into a detailed, comprehensive technical question. "
        "Add relevant context, clarify ambiguous terms, and make implicit requirements explicit. "
        "Return only the expanded query without explanations."
    )

    response = openai_client.chat.completions.create(
        model=settings.llm_model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query},
        ],
        temperature=0.3,
    )

    expanded = response.choices[0].message.content or query
    logger.debug("Expanded query: %s -> %s", query, expanded)
    return expanded.strip()


def generate_multi_queries(
    query: str, n: int = 3, openai_client: OpenAI | None = None
) -> list[str]:
    """Generate n alternative formulations of the query using LLM.

    Args:
        query: Original query to reformulate
        n: Number of alternative queries to generate
        openai_client: Optional OpenAI client instance

    Returns:
        List of n alternative query formulations
    """
    if openai_client is None:
        from openai import OpenAI

        openai_client = OpenAI(api_key=settings.openai_api_key)

    system_prompt = (
        f"You are a query reformulation expert. "
        f"Generate {n} alternative formulations of the user's query. "
        f"Each formulation should capture the same intent but use different wording, "
        f"perspectives, or technical terminology. "
        f"Return exactly {n} queries, one per line, without numbering or explanations."
    )

    response = openai_client.chat.completions.create(
        model=settings.llm_model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query},
        ],
        temperature=0.7,
    )

    content = response.choices[0].message.content or ""
    queries = [q.strip() for q in content.strip().split("\n") if q.strip()]

    # Ensure we have exactly n queries
    if len(queries) < n:
        queries.extend([query] * (n - len(queries)))
    elif len(queries) > n:
        queries = queries[:n]

    logger.debug("Generated %d multi-queries for: %s", len(queries), query)
    return queries
